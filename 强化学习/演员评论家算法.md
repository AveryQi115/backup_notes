# 演员评论家算法

- 演员是策略函数，输入s，输出a，学习一个策略来得到尽量高的回报
- 评论家是指函数，输入s，利用当前策略$\pi$，输出V，对当前策略的值函数进行估计，评估演员的好坏



- 演员(动作)网络输入s，输出a，优化目标：a输入评论家网络后使得Q值最大的a
- 评论家(值)网络输入s，a，输出Q
  - 架构：3层cnn，2层全连接，+a求和，3层全连接



## 设计逻辑：

- 动作：网络a，目标网络a‘
  - 3层cnn，2层全连接
  - 输出长度为50的向量，*乘子b缩放范围到node数

- 评论家：网络q，目标网络q’



- generate buffer： s_t,-->动作-->a_t 应用a_t-->s_t+1获得reward r_t

- Train:
  - q(s_t,a_t)
  - freeze q', s'
  - y = r_t + $\lambda$q'(s_t+1,a'(s_t+1))
  - Loss_for_q = \sqrt((y-q(s_t,a_t))^2/N)
  - freeze q
  - q(s_t,a_t(s_t)) loss backward
  - Loss_for_a = -q(s_t,a_t(s_t)) (可以改成gan loss)
  - 每隔几个patch浮动更新q‘和a'